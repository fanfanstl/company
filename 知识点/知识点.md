# 知识点

## 设置断点

```
设置断点：
	import pdb
	pdb.set_trace()
	c继续执行
```

```
jkids_hara 第二天任务
启动命令：scrapy crawl denaec  -a taskId=1231 -a taskType='spider_update' -a sourceUrls='["https://wowma.jp/item/307857399?l=true%26e%3DllA%26e2%3Dlisting_flpro"]'
```

## git命令

```
git diff [filename] 比对文件前后差异
git status 查看当前状态
git commit -m "describe " [filename] 将单个文件提交到本地仓库
git push origin master 推到远程仓库上
```

## 断言

```
断言会抛出异常
```

## scrapy中添加headers

![1551681477292](D:\360MoveData\Users\fanding\Desktop\company\知识点\1551681477292.png)

## scrapy中添加cookie

可以同上，在headers中添加cookie

![1551681743109](D:\360MoveData\Users\fanding\Desktop\company\知识点\1551681743109.png)

## git解决冲突

```
git checkout [文件名] ：从远程仓库同步代码
git pull :同步下来
然后git push origin master
```

## phantomjs使用

```

```

## selenium使用

```

```

## linux14.04安装docker

```
1、使用 sudo or root 权限登陆计算机.

2、打开 terminal window（命令窗口）.

3、更新安装包信息, 确保 APT 使用 https 协议, 同时CA 证书已经被安装.

 $ sudo apt-get update
 $ sudo apt-get install apt-transport-https ca-certificates
4、添加新的GPGkey.

$ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D
5、用编辑器打开  /etc/apt/sources.list.d/docker.list.
如果不存在，则新建一个
删除任何现有输入.

6、添加与您Ubuntu操作系统相关条目。

该条目可以是：

On Ubuntu Precise 12.04 (LTS)

deb https://apt.dockerproject.org/repo ubuntu-precise main
On Ubuntu Trusty 14.04 (LTS)

deb https://apt.dockerproject.org/repo ubuntu-trusty main
Ubuntu Wily 15.10

deb https://apt.dockerproject.org/repo ubuntu-wily main
Ubuntu Xenial 16.04 (LTS)

deb https://apt.dockerproject.org/repo ubuntu-xenial main

7、更新APT 软件包索引.

$ sudo apt-get update
9、清除旧的repo if it exists.

$ sudo apt-get purge lxc-docker
10、确保 APT 是从正确的代码库拉取下来的.

$ apt-cache policy docker-engine

11、Update your APT package index.

$ sudo apt-get update
12、安装 Docker.

$ sudo apt-get install docker-engine
13、开始使用docker.

$ sudo service docker start
14、确认docker已被正确安装.

$ sudo docker run hello-world
```

## 环境搭建

![1552228408765](D:\360MoveData\Users\fanding\Desktop\company\知识点\1552228408765.png)

## 反爬虫

1、除了xhr请求还有可能是在js中，还有就是可能是js构造出来的数据









## 数据库配置文件

newWebsite.conf中添加spider的名字



## 单独运行某个详情页

scrapy crawl denaec  -a taskId=1231 -a taskType='spider_update' -a sourceUrls='["https://wowma.jp/item/307857399?l=true%26e%3DllA%26e2%3Dlisting_flpro"]'



## 脚本上线流程

后台进入操作：

品牌管理--->供应商品牌审核---->新增供应商品牌

配置：

供应商：spider_name

转运国家：品牌的发货地

源品牌：脚本里配置的，也可能是动态抓取出来的

棒棒糖品牌：邮件里写明的，注意确认、确认

品牌国家：邮件里有写明



运行spider

单品管理--->抓取任务列表----->添加任务

解释：

​	任务类型：spider：抓取全网    spider_update：抓取配置好的部分东西

​	网站：spider_name

​	更新库存：更新价格和库存

​	导入新品：导入新的商品

​	更新图片：更新图片



上线跑完以后检测流程：

​	单品管理--->上新列表---->核对信息

## FormRequest中的from_response方法

![1553074137525](D:\360MoveData\Users\fanding\Desktop\company\知识点\1553074137525.png)

## 抓取报警处理流程

1、进入线上抓取库

2、到后台任务列表中找到报警spider的taskId

2、查看错误日志

select * from spider_log where taskId=taskId

根据错误日志进行排错

## 采购报警处理

1、进入后台--->采购任务列表，搜索有问题的spidername

2、查看详情，找到在哪台主机上运行，并且找出任务id

3、进入该主机

4、进入到/home/work 目录下

5、grep 856038 spider-online-*/log/spider.log.2019032115

6、grep janieandjack spider-online-9/log/spider.log.2019032115

